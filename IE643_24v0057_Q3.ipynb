{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRbe9qI46gf8OFnwSxlaXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohini57/IE643-24v0057assignment1/blob/main/IE643_24v0057_Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lNrOXedwNNu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the MultiLabelData dataset\n",
        "data = pd.read_csv(\"MultiLabelData.csv\")\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.iloc[:, :294].values\n",
        "y = data.iloc[:, 294:].values\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have loaded the data into X (features) and y (labels)\n",
        "\n",
        "# Shuffle the data\n",
        "np.random.seed(42)  # Set a random seed for reproducibility\n",
        "shuffled_indices = np.random.permutation(len(X))\n",
        "X = X[shuffled_indices]\n",
        "y = y[shuffled_indices]\n",
        "# Split into training, validation, and testing sets\n",
        "S1_size = int(0.7 * len(X))\n",
        "S2_size = int(0.15 * len(X))\n",
        "\n",
        "X_train, X_temp, y_train\n",
        ", y_temp = train_test_split(X, y, test_size=1 - 0.7, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Assign the splits to S1, S2, and S3\n",
        "S1 = (X_train, y_train)\n",
        "S2 = (X_val, y_val)\n",
        "S3 = (X_test, y_test)\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have S1, S2, and S3 as tuples of (X, y)\n",
        "S1_X, S1_y = S1\n",
        "S2_X, S2_y = S2\n",
        "S3_X, S3_y = S3\n",
        "\n",
        "# Create DataFrames for each split\n",
        "S1_df = pd.DataFrame(S1_y, columns=[\"label1\", \"label2\", \"label3\", \"label4\", \"label5\", \"label6\"])\n",
        "S2_df = pd.DataFrame(S2_y, columns=[\"label1\", \"label2\", \"label3\", \"label4\", \"label5\", \"label6\"])\n",
        "S3_df = pd.DataFrame(S3_y, columns=[\"label1\", \"label2\", \"label3\", \"label4\", \"label5\", \"label6\"])\n",
        "\n",
        "# Calculate label distributions for each split\n",
        "S1_label_dist = S1_df.sum(axis=0) / len(S1_df)\n",
        "S2_label_dist = S2_df.sum(axis=0) / len(S2_df)\n",
        "S3_label_dist = S3_df.sum(axis=0) / len(S3_df)\n",
        "\n",
        "# Print the label distributions\n",
        "print(\"Label Distribution for S1:\")\n",
        "print(S1_label_dist)\n",
        "\n",
        "print(\"\\nLabel Distribution for S2:\")\n",
        "print(S2_label_dist)\n",
        "\n",
        "print(\"\\nLabel Distribution for S3:\")\n",
        "print(S3_label_dist)\n",
        "import numpy as np\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    \"\"\"Calculates the binary cross-entropy loss.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels.\n",
        "        y_pred: Predicted probabilities.\n",
        "\n",
        "    Returns:\n",
        "        The binary cross-entropy loss.\n",
        "    \"\"\"\n",
        "\n",
        "    epsilon = 1e-7  # Small value to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n",
        "    )\n",
        "    import numpy as np\n",
        "\n",
        "def compute_map(y_true, y_pred):\n",
        "    \"\"\"Computes the mean average precision (MAP) for multi-label classification.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels (n_samples, n_labels).\n",
        "        y_pred: Predicted probabilities (n_samples, n_labels).\n",
        "\n",
        "    Returns:\n",
        "        The mean average precision (MAP).\n",
        "    \"\"\"\n",
        "\n",
        "    n_samples, n_labels = y_true.shape\n",
        "    map_scores = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        y_true_i = y_true[i]\n",
        "        y_pred_i = y_pred[i]\n",
        "\n",
        "        # Sort predicted probabilities in descending order\n",
        "        sorted_indices = np.argsort(y_pred_i)[::-1]\n",
        "        y_true_i = y_true_i[sorted_indices]\n",
        "        y_pred_i = y_pred_i[sorted_indices]\n",
        "\n",
        "        # Calculate precision and recall for each rank\n",
        "        precision = np.cumsum(y_true_i) / np.arange(1, n_labels + 1)\n",
        "        recall = np.cumsum(y_true_i) / np.sum(y_true_i)\n",
        "\n",
        "        # Calculate average precision\n",
        "        average_precision = np.sum(precision[y_true_i == 1] * recall[y_true_i == 1]) / np.sum(y_true_i)\n",
        "        map_scores.append(average_precision)\n",
        "\n",
        "    # Calculate mean average precision\n",
        "    map_score = np.mean(map_scores)\n",
        "    return map_score\n",
        "    # Assuming you have y_true and y_pred\n",
        "map_score = compute_map(y_true, y_pred)\n",
        "print(\"MAP:\", map_score)\n",
        "def train_model(X_train, y_train, X_val, y_val, learning_rate, batch_size, num_epochs):\n",
        "    # ... (Your implementation of mini-batch SGD)\n",
        "\n",
        "    losses_train = []\n",
        "    losses_val = []\n",
        "    map_scores_train = []\n",
        "    map_scores_val = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ... (Mini-batch SGD training loop)\n",
        "\n",
        "        # Calculate loss and MAP on training and validation sets\n",
        "        loss_train = calculate_loss(X_train, y_train, model)\n",
        "        loss_val = calculate_loss(X_val, y_val, model)\n",
        "        map_train = compute_map(y_train, model.predict(X_train))\n",
        "        map_val = compute_map(y_val, model.predict(X_val))\n",
        "\n",
        "        losses_train.append(loss_train)\n",
        "        losses_val.append(loss_val)\n",
        "        map_scores_train.append(map_train)\n",
        "        map_scores_val.append(map_val)\n",
        "\n",
        "    return losses_train, losses_val, map_scores_train, map_scores_val\n",
        "\n",
        "# Hyperparameter grid\n",
        "learning_rates = [0.1, 0.01, 0.001, 1e-4]\n",
        "batch_sizes = [8, 16, 32]\n",
        "\n",
        "# Train the model for each hyperparameter combination\n",
        "results = {}\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        losses_train, losses_val, map_scores_train, map_scores_val = train_model(S1_X, S1_y, S2_X, S2_y, lr, bs, 200)\n",
        "        results[(lr, bs)] = (losses_train, losses_val, map_scores_train, map_scores_val)\n",
        "\n",
        "# Plot the results (replace with your plotting library)\n",
        "# ...\n",
        "\n",
        "# Select the best hyperparameters based on validation loss and MAP\n",
        "best_lr, best_bs = None, None\n",
        "best_val_loss = float('inf')\n",
        "best_val_map = 0.0\n",
        "\n",
        "for lr, bs in results:\n",
        "    losses_val, map_scores_val = results[(lr, bs)][1:3]\n",
        "    if losses_val[-1] < best_val_loss and map_scores_val[-1] > best_val_map:\n",
        "        best_lr, best_bs = lr, bs\n",
        "        best_val_loss = losses_val[-1]\n",
        "        best_val_map = map_scores_val[-1]\n",
        "\n",
        "print(\"Best learning rate:\", best_lr)\n",
        "print(\"Best mini-batch size:\", best_bs)\n",
        "def train_model_with_early_stopping(X_train, y_train, X_val, y_val, X_test, y_test, learning_rate, batch_size, num_epochs, patience=10):\n",
        "    # ... (Your implementation of mini-batch SGD)\n",
        "\n",
        "    # ... (Similar to the previous training code)\n",
        "\n",
        "    best_val_map = 0.0\n",
        "    no_improvement_epochs = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ... (Mini-batch SGD training loop)\n",
        "\n",
        "        # Calculate loss and MAP on training, validation, and testing sets\n",
        "        # ...\n",
        "\n",
        "        # Early stopping\n",
        "        if map_val > best_val_map:\n",
        "            best_val_map = map_val\n",
        "            no_improvement_epochs = 0\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "            if no_improvement_epochs >= patience:\n",
        "                break\n",
        "\n",
        "    return losses_train, losses_val, losses_test, map_scores_train, map_scores_val, map_scores_test\n",
        "\n",
        "# Use the best hyperparameters from previous experiments\n",
        "best_lr = 0.01  # Example\n",
        "best_bs = 16  # Example\n",
        "#Observations:\n",
        "\n",
        "Loss: You might observe a decreasing trend in the training loss, but the validation and testing losses might plateau or even increase after a certain number of epochs, indicating overfitting.\n",
        "MAP: The validation and testing MAP should initially increase, but eventually plateau or start to decrease if overfitting occurs.\n",
        "Early Stopping: The early stopping mechanism should help prevent overfitting by stopping training when the validation MAP stops improving significantly.\n",
        "#Q3i\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Assuming you have y_true_test and y_pred_test for the testing set\n",
        "\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_test, average=None)\n",
        "\n",
        "# Print the results\n",
        "for i in range(6):\n",
        "    print(f\"Label {i+1}:\")\n",
        "    print(f\"  Precision: {precision[i]:.3f}\")\n",
        "    print(f\"  Recall: {recall[i]:.3f}\")\n",
        "    print(f\"  F1-score: {f1_score[i]:.3f}\")\n",
        "    # Calculate class weights based on inverse frequency\n",
        "class_weights = np.sum(y_train, axis=0) / np.sum(y_train)\n",
        "class_weights = 1 / class_weights\n",
        "\n",
        "# Modify your loss function to include class weights\n",
        "def weighted_binary_cross_entropy(y_true, y_pred, class_weights):\n",
        "    # ... (Your original binary cross-entropy implementation)\n",
        "    loss *= class_weights\n",
        "    #Class weights are calculated based on the inverse frequency of each label in the training set.\n",
        "The loss function is modified to multiply the loss for each sample by its corresponding class weight.\n",
        "This effectively gives more importance to underrepresented or difficult labels during training.\n"
      ]
    }
  ]
}